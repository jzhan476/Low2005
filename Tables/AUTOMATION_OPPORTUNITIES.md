# Table Generation Automation Opportunities

This document analyzes which tables could be better automated by programmatically generating them from computational outputs.

## Current Status Summary

| Table | Current Method | Automation Potential | Priority |
|-------|---------------|---------------------|----------|
| **calibration.tex** | Hardcoded | Low (rarely changes) | Low |
| **MPC_WQ.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |
| **Comparison_Splurge_Table.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |
| **estimBetas.tex** | ‚ö†Ô∏è Manual transcription | **HIGH** - All data in AllResults | **HIGH** |
| **nonTargetedMoments.tex** | ‚ö†Ô∏è Manual transcription | **HIGH** - All data in AllResults | **HIGH** |
| **calibrationRecession.tex** | Hardcoded | Medium (could extract from code) | Medium |
| **Multiplier.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |
| **welfare6.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |
| **Multiplier_SplurgeComp.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |
| **welfare6-SplurgeComp.tex** | ‚úÖ **Fully Automated** | N/A - Already done | N/A |

## Detailed Analysis

### ‚úÖ Already Fully Automated (5/10 tables)

These tables are already programmatically generated:

1. **MPC_WQ.tex**
   - Generated by: `Estimation_BetaNablaSplurge.py` (line 680)
   - Output: `Figures/MPC_WealthQuartiles_Table.ltx`
   - Status: ‚úÖ No action needed

2. **Comparison_Splurge_Table.tex**
   - Generated by: `Estimation_BetaNablaSplurge.py` (line 667)
   - Output: `Figures/Comparison_Splurge_Table.tex`
   - Status: ‚úÖ No action needed

3. **Multiplier.tex**
   - Generated by: `Output_Results.py` (line 479)
   - Output: `FromPandemicCode/Tables/CRRA2/Multiplier.ltx`
   - Status: ‚úÖ No action needed

4. **welfare6.tex**
   - Generated by: `Welfare.py` (line 293)
   - Output: `FromPandemicCode/Tables/CRRA2/welfare6.ltx`
   - Status: ‚úÖ No action needed

5. **Multiplier_SplurgeComp.tex** & **welfare6-SplurgeComp.tex**
   - Similar to above but for splurge comparison
   - Status: ‚úÖ No action needed

---

## üî¥ HIGH PRIORITY: Should Be Automated

### 1. estimBetas.tex (Table 4)

**Current**: Manual transcription from `AllResults_CRRA_2.0_R_1.01.txt`

**What's Available in AllResults**:

```
Line 4:  Education group = 0.00: beta = 0.7190, nabla = 0.3175
Line 5:  Median LW/PI-ratio = 4.64
Line 10: [0.4468 0.5375 0.6282 0.719 0.8097 0.9004 0.9911]

Line 14: Education group = 1.00: beta = 0.9246, nabla = 0.0768
Line 15: Median LW/PI-ratio = 30.16
Line 20: [0.8588 0.8807 0.9026 0.9246 0.9465 0.9684 0.9904]

Line 24: Education group = 2.00: beta = 0.9826, nabla = 0.0139
Line 25: Median LW/PI-ratio = 112.80
Line 30: [0.9707 0.9746 0.9786 0.9826 0.9865 0.9905 0.9945]
```

**What the Table Needs**:

- Panel A: (Œ≤, ‚àá) for each education group ‚Üê Lines 4, 14, 24
- Panel A: (Min, Max) from approximation ‚Üê Lines 10, 20, 30 (first and last values)
- Panel B: Median LW/PI (data) ‚Üê From SCF (hardcoded or from `make_liquid_wealth.do`)
- Panel B: Median LW/PI (model) ‚Üê Lines 5, 15, 25

**Implementation**:

```python
def generate_estimBetas_table():
    """Parse AllResults file and generate estimBetas.ltx"""
    # Read AllResults_CRRA_2.0_R_1.01.txt
    # Extract lines 4, 5, 10, 14, 15, 20, 24, 25, 30
    # Parse beta, nabla, median values, min/max
    # Format as LaTeX tabular
    # Write to Tables/estimBetas.ltx
```

**Suggested Location**: Add to `EstimAggFiscalMAIN.py` after writing AllResults file

**Effort**: üü¢ Low (2-3 hours) - Straightforward text parsing and formatting

---

### 2. nonTargetedMoments.tex (Table 5)

**Current**: Manual transcription from `AllResults_CRRA_2.0_R_1.01.txt` and `make_liquid_wealth.do`

**What's Available in AllResults**:

```
Line 37: Wealth shares by Ed.= [1.207, 16.826, 81.968]
Line 38: Wealth Shares by Wealth Q = [0.12, 0.98, 3.85, 95.06]
Line 44: Average lottery-win-year MPCs by Wealth (incl. splurge) = [0.74, 0.609, 0.475, 0.324, 0.537]
Line 45: Average lottery-win-year MPCs by Education (incl. splurge) = [0.777, 0.606, 0.383, 0.537]
```

**What the Table Needs**:

**Panel A** (by education group):

- Line 1: Percent of liquid wealth (data) ‚Üê From SCF (hardcoded: [0.8, 17.9, 81.2])
- Line 2: Percent of liquid wealth (model) ‚Üê Line 37: [1.2, 16.8, 82.0] ‚úì
- Line 3: Avg. lottery-win-year MPC ‚Üê Line 45: [0.78, 0.61, 0.38, 0.54] ‚úì

**Panel B** (by wealth quartile):

- Line 1: Percent of liquid wealth (data) ‚Üê From SCF (hardcoded: [0.14, 1.60, 8.51, 89.76])
- Line 2: Percent of liquid wealth (model) ‚Üê Line 38: [0.12, 0.98, 3.85, 95.06] ‚úì
- Line 3: Avg. lottery-win-year MPC ‚Üê Line 44: [0.74, 0.61, 0.48, 0.32] ‚úì

**Implementation**:

```python
def generate_nonTargetedMoments_table():
    """Parse AllResults file and generate nonTargetedMoments.ltx"""
    # Read AllResults_CRRA_2.0_R_1.01.txt
    # Extract lines 37, 38, 44, 45
    # Hardcode empirical wealth shares from SCF
    # Format as two-panel LaTeX tabular
    # Write to Tables/nonTargetedMoments.ltx
```

**Suggested Location**: Add to `EstimAggFiscalMAIN.py` after writing AllResults file

**Effort**: üü¢ Low (2-3 hours) - Similar to estimBetas

---

## üü° MEDIUM PRIORITY: Could Be Automated

### 3. calibrationRecession.tex (Table 3)

**Current**: Hardcoded parameter values

**What's Available in Code**:
All parameters are defined in `FromPandemicCode/Parameters.py`:

- Recession unemployment duration: `Uspell_recession`
- Unemployment exit probability: `1/Uspell_recession`
- Unemployment rates by education: `Urate_recession_d/h/c`
- Entry probabilities: Calculated from unemployment rates
- Policy parameters: `AvgRecessionLength`, `StimCheck`, `ExtendUI`, etc.

**Implementation**:

```python
def generate_calibrationRecession_table(params_dict):
    """Extract recession parameters and generate calibrationRecession.ltx"""
    # Read parameters from Parameters.py or pass as dict
    # Calculate entry/exit probabilities
    # Format as three-panel LaTeX tabular
    # Write to Tables/calibrationRecession.ltx
```

**Suggested Location**: Add to `Parameters.py` or create new `generate_tables.py` script

**Effort**: üü° Medium (4-6 hours) - Requires careful parameter extraction and calculation

**Benefit**: Moderate - Parameters don't change often, but automation reduces errors

---

### 4. calibration.tex (Table 2)

**Current**: Hardcoded parameter values

**What's Available in Code**:
All parameters are defined in `FromPandemicCode/EstimParameters.py`:

- CRRA, Splurge (from Result_AllTarget.txt), LivPrb, Rfree, etc.
- Standard deviations: TranShkStd, PermShkStd
- UI parameters: IncUnemp, IncUnempNoBenefits, UBspell_normal, Uspell_normal
- Education-specific: Population shares, initial PI, growth factors, unemployment rates
- Aggregate demand: ADelasticity

**Implementation**:

```python
def generate_calibration_table(params_dict, splurge_from_estimation):
    """Extract calibration parameters and generate calibration.ltx"""
    # Read parameters from EstimParameters.py
    # Read splurge from Result_AllTarget.txt
    # Format as two-panel LaTeX tabular
    # Write to Tables/calibration.ltx
```

**Suggested Location**: Create `generate_calibration_tables.py` script

**Effort**: üü° Medium (4-6 hours) - Many parameters to extract and format

**Benefit**: Low - Parameters very stable, but ensures consistency

---

## üü¢ LOW PRIORITY: Already Optimal

These tables don't need automation:

- Tables with no computational results (just text/equations)
- Tables that change with each paper revision (manual editing needed)
- Tables that are already fully automated

---

## Recommended Implementation Plan

### Phase 1: High-Value Quick Wins (1 week)

1. **estimBetas.tex automation**
   - Add `generate_estimBetas_table()` to `EstimAggFiscalMAIN.py`
   - Call after writing `AllResults_CRRA_2.0_R_1.01.txt`
   - Test with existing results file

2. **nonTargetedMoments.tex automation**
   - Add `generate_nonTargetedMoments_table()` to `EstimAggFiscalMAIN.py`
   - Call after writing `AllResults_CRRA_2.0_R_1.01.txt`
   - Test with existing results file

### Phase 2: Parameter Tables (Optional, 1 week)

3. **calibrationRecession.tex automation**
   - Create `generate_parameter_tables.py` utility script
   - Import parameters from `Parameters.py`
   - Generate table

4. **calibration.tex automation**
   - Add to `generate_parameter_tables.py`
   - Import parameters from `EstimParameters.py`
   - Generate table

---

## Code Template

Here's a template for implementing table generation:

```python
# Add to EstimAggFiscalMAIN.py or create generate_tables.py

import re
import os

def parse_allresults(filepath):
    """Parse AllResults file and return structured data"""
    results = {
        'dropout': {}, 
        'highschool': {}, 
        'college': {},
        'population': {}
    }
    
    with open(filepath, 'r') as f:
        lines = f.readlines()
    
    # Parse education group 0 (dropout)
    results['dropout']['beta'] = float(re.search(r'beta = ([\d.]+)', lines[3]).group(1))
    results['dropout']['nabla'] = float(re.search(r'nabla = ([\d.]+)', lines[3]).group(1))
    results['dropout']['median_lw_pi'] = float(re.search(r'= ([\d.]+)', lines[4]).group(1))
    # ... etc
    
    return results

def generate_estimBetas_ltx(results, output_path):
    """Generate estimBetas.ltx from parsed results"""
    
    # Data values (hardcoded from SCF)
    data_median = [4.64, 30.2, 112.8]
    
    output = "\\begin{tabular*}\n"
    output += "  {\\textwidth}{@{\\extracolsep{\\fill}}lccc@{}}\n"
    output += "  \\multicolumn{4}{c}{\\small Panel A: Estimated discount factor distributions} \\\\\n"
    output += "  \\addlinespace\n"
    output += "  \\hline\n"
    output += "  & Dropout & Highschool & College \\\\ \\hline\n"
    
    # Format (beta, nabla)
    output += f"  $(\\beta_e, \\nabla_e)$ & "
    output += f"({results['dropout']['beta']:.3f}, {results['dropout']['nabla']:.3f}) & "
    output += f"({results['highschool']['beta']:.3f}, {results['highschool']['nabla']:.3f}) & "
    output += f"({results['college']['beta']:.3f}, {results['college']['nabla']:.3f}) \\\\\n"
    
    # ... etc
    
    with open(output_path, 'w') as f:
        f.write(output)
    
    print(f"‚úÖ Generated {output_path}")

# Example usage in EstimAggFiscalMAIN.py (after line 1111):
if True:  # Set to True to enable table generation
    results_file = os.path.join(Abs_Path_Results, 'AllResults_CRRA_2.0_R_1.01.txt')
    results = parse_allresults(results_file)
    
    generate_estimBetas_ltx(
        results, 
        os.path.join(Abs_Path_Results, '../../../Tables/estimBetas.ltx')
    )
    
    generate_nonTargetedMoments_ltx(
        results,
        os.path.join(Abs_Path_Results, '../../../Tables/nonTargetedMoments.ltx')
    )
```

---

## Benefits of Automation

### Reproducibility

- No manual transcription errors
- Results automatically update when re-running computations
- Clear provenance of all numbers

### Efficiency

- Saves ~30 minutes per table update
- Reduces error-checking time
- Enables batch regeneration of all tables

### Consistency

- Same formatting across all automated tables
- Parameter values guaranteed to match code
- Easier to maintain multiple parametrizations

---

## Current Best Practices

The project already follows excellent practices:

1. ‚úÖ Most policy result tables are automated (Multiplier, welfare6)
2. ‚úÖ Core estimation output (MPC_WQ, Comparison_Splurge) is automated
3. ‚úÖ Clear documentation in `do_all-README.md` of table provenance

The main gap is **validation/non-targeted moment tables** that are computed but manually transcribed.

---

## Questions for Discussion

1. **Priority**: Should we prioritize automating estimBetas and nonTargetedMoments?
2. **Scope**: Should parameter tables (calibration, calibrationRecession) also be automated?
3. **Location**: Keep table generation in main scripts or create separate `generate_tables.py`?
4. **Testing**: How to validate that automated tables match current manual versions?

---

## Summary

**High-Value Automation Opportunities**:

- ‚úÖ **estimBetas.tex**: All data in AllResults (lines 4-30)
- ‚úÖ **nonTargetedMoments.tex**: All data in AllResults (lines 37-45)

**Estimated Effort**: 4-6 hours for both high-priority tables

**Estimated Benefit**: Eliminates manual transcription errors, improves reproducibility, saves time on every computational run
